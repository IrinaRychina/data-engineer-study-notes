> source https://halltape.github.io/HalltapeRoadmapDE/QUESTION/Hadoop/
* Что такое Hadoop и из каких компонентов он состоит?
это инструмент (экосистема приложений) для распределенного хранения и обработки больших данных.
Состоит из 4 основных компонентов:
1. hdfs - hadoop distributed file system, распределенная файловая система, технология хранения файлов на различных серверах 
(узлах, Datanodes), адреса которых находятся на специальном сервере NameNode.
За счет репликации данных hdfs обеспечивает надежное хранение файлов больших размеров.
2. hadoop common - содержит библиотеки и утилиты, которые нужны остальным модулям hadoop
3. hadoop yarn - плтаформа ответственная за управление вычислительными ресурсами в кластерах и планирование выполнения заданий. 
4. hadoop mapreduce - это реализация модели программирования MapReduce для вычисления заданий над большими данными.

* Что такое YARN?
это система управления ресурсами в экосистеме хадуп, которая позволяет распределять и планировать вычислительные ресурсы для запуска приложений на кластере.
Действует как ос на уровне кластера, управляя узоами и распределяя ресурсы (память, cpu) между приложениями.
Служит интерфейсом между аппаратными ресурсами кластера и приложения, которые используют эти ресурсы для обработки больших данных.

* Для чего нужен Apache Oozie?
это система планирования рабочих процессов для управления задачами хадуп.
последовательность выполнения рабочих процессов задана в ациклическом ориентированном графе.
Это оркестратор как и airflow, но ориентированный на хадуп.

* Что такое Hive и объясни, как он работает с данными?
это система, которая предоставляет доступ к большим наборам данных, хранящихся в распределенных системах, например, на hdfs, 
используя знакомый разработчикам sql- подобный язык hiveql.
Hive позволяет проектировать струкутуру для больших данных, превращая их в таблицы, которые затем можно запрашивать, 
агрегировать и анализировать как в традиционных реляционных субд, без необходимости глубоких знаний mapreduce.
  (позволяет определить схему/структуру ланных, которые хранятся в hdfs, и представить эти данные в виде таблиц, которые можно разбивать на партиции и бакеты.)

* Объясни парадигму MapReduce и почему Spark пришел ей на замену?
недостатки MapReduce:
1. невысокая производительность - вычисления производятся в 2 этапа, при этом MapReduce регулярно обращается к диску.
Таким образом модель функционирует с задержками, это ограничивает применение MapReduce в потоковой обработке данных и в решении задач machine-learning.  
2. повышенная сложность - нужен высокий уровень экспертности от разработчика.

Достоинства спарк:
1. выполняет вычисления в оперативной памяти, если данных больше чем объем ram, то сбрасывает данные на диск.
Поэтому спарк быстрее MapReduce во много раз.
2. в спарк существует апи для разных языков, из-за чего писать код для него проще, разработчики пишут высокоуровневые интсрукции, а как их лучше выполнить решает сам спарк.

* Как работает HDFS?
это распределенная файловая система, которая работает путем разделения больших файлов на блоки и их хранения на множестве серверов (DataNodes) в кластере.
Главный сервер NameNode управляет этими блоками и хранит метаданные, а данные реплицируются, чтобы обеспечить устойчивость данных.
Принципы работы:
1. разбиение данных на блоки фиксированного размера
2. репликация блоков, обычно 3 копии (достаточно устойчиво и не слишком много)
3. распределние блоков и их реплик по всему кластеру
4. hdfs разработан для сценариев "однократная запись и многократное чтение".
5. Отказоустойчивость: если датанода вышла из строя, то namenode определяет это по отсутствию heartbeats и инициирует создание реплиу на других узлах.

Преимущества:
1. откзоустойчивость - атоматическая репликация предотвращает потерю данных 
2. масштабируемость
3. высокая пропускная способность благодаря параллельной обработке

* Для чего нужна NameNode, Secondary NameNode?
NameNode – это управляющий узел HDFS, который хранит всю метаинформацию о файловой системе (структуру каталогов, расположение 
блоков данных) и не хранит сами данные. 
NameNode не хранит сами данные, а выступает в роли "индекса" или "карты" распределенной файловой системы.

Secondary NameNode 
Не является резервной копией NameNode, а служит для ускорения процесса восстановления после сбоя. 
Периодически считывает журнал изменений (EditLog) с NameNode. 
Применяет эти изменения к основному образу файловой системы (FSImage). 
Сохраняет новый, объединенный образ и очищает журнал EditLog, предотвращая его бесконечное разрастание.
Таким образом при перезапуске NameNode ему не нужно обрабатывать большой накопленный журнал, так как Secondary NameNode 
уже создал актуальный образ FSImage с примененными изменениями

* Нам необходимо считать текстовый файл из HDFS, объясни, что будет происходить?
При считывании текстового файла из HDFS (Hadoop Distributed File System) клиент отправляет запрос к узлу NameNode для 
получения информации о расположении блоков файла, а затем получает сами блоки данных напрямую от узлов DataNode. 
В результате клиент собирает и возвращает данные файла напряму от узлов DataNode.
После получения всех блоков клиент объединяет их в исходный файл и возвращает данные пользователю или другому приложению.


* Что такое партиционирование и что оно из себя представляет в Hadoop?
Партиционирование (или разбиение на разделы) — это техника разделения больших наборов данных на более мелкие, 
управляемые секции (партиции), что позволяет оптимизировать производительность путем сокращения объема обрабатываемых 
данных для каждого запроса. В Hadoop и связанных с ним инструментах, таких как Hive и Spark, партиционирование реализуется 
физическим разделением данных на различные каталоги в файловой системе HDFS. Это позволяет системам сканировать только 
нужные разделы, игнорируя остальные, что значительно ускоряет выполнение запросов, особенно при наличии фильтров по столбцам 
партиционирования, таких как дата или страна

В Hadoop и его инструментах (например, Apache Hive) партиционирование означает физическое размещение данных в разных 
каталогах файловой системы HDFS, где каждый каталог соответствует определенному значению партиционирующего столбца.

Когда вы создаете партиционированную таблицу, Hive или Spark автоматически разделяет данные по указанным столбцам 
(например, по году или месяцу) и сохраняет их в подкаталогах HDFS.

Партиционирование очень удобно для разделения данных по дате (например, логи по дням или месяцам), региону или любому 
другому столбцу, по которому часто проводится фильтрация

ограничения:
1. Много партиций: Создание чрезмерно большого количества партиций (например, по каждому дню для десятилетней таблицы) может негативно 
сказаться на производительности, так как возрастает нагрузка на файловую систему и увеличивается количество операций ввода-вывода.
2. Неравномерность данных:
Если значения партиционирующего столбца распределены крайне неравномерно (например, много данных для одного года и мало 
для другого), это может привести к дисбалансу нагрузки.

* Что такое фактор репликации в HDFS и для чего он нужен?
Фактор репликации в HDFS — это параметр, определяющий, сколько раз каждый блок данных файла будет скопирован и 
сохранен на разных узлах (DataNode) в кластере. Его основная функция — обеспечить отказоустойчивость: при выходе из 
строя одного или нескольких узлов данные остаются доступными из оставшихся копий, что предотвращает потерю данных и 
гарантирует высокую доступность системы. 

* Что такое HDFS блоки и какие у них есть минусы?
HDFS блоки – это фрагменты больших файлов фиксированного размера (по умолчанию 128 МБ), на которые 
HDFS (Hadoop Distributed File System) разделяет данные для распределенного хранения и обработки на узлах кластера. 
Основной минус HDFS блоков заключается в неэффективности работы с большим количеством 
мелких файлов, которые занимают много места в пространстве имен, но фактически неэффективно используют дисковое 
пространство из-за неполного заполнения блока.

* Как бороться с маленькими файлами в HDFS? Переполнение NameNode

Почему маленькие файлы вызывают проблемы:

Переполнение памяти NameNode:
Каждый файл в HDFS требует хранения метаданных в памяти NameNode. Большое количество мелких файлов означает,
что NameNode приходится хранить гораздо больше информации о каждом файле, что приводит к исчерпанию его оперативной памяти.
Снижение производительности:
Сканирование большого количества мелких файлов для их объединения требует большего количества операций ввода-вывода, что замедляет обработку.

Для борьбы с проблемой маленьких файлов, приводящей к переполнению NameNode в HDFS, следует объединять небольшие файлы 
в более крупные с помощью инструментов вроде Spark или команды hdfs dfs -getmerge. Также можно 
использовать архивацию, например, с помощью формата HAR (Hadoop Archive), или применять сжатие перед записью данных, 
чтобы уменьшить объем метаданных, хранимых NameNode

* Если мы записываем файл размером меньше 128Мб, то какого размера будет блок нового файла?
Если вы записываете файл размером меньше 128 МБ в систему, использующую блоки размером 128 МБ (например, HDFS), то файл 
будет записан в один блок меньшего размера, который будет использоваться 
только для этого файла. Это означает, что весь файл, независимо от его реального размера, будет занимать один блок, 
а оставшееся место в блоке останется неиспользованным

